{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2B Data Analysis\n",
    "\n",
    "[E2B's cloud environments](https://e2b.dev) are great runtime sandboxes for LLMs.\n",
    "\n",
    "E2B's Data Analysis sandbox allows for safe code execution in a sandboxed environment. This is ideal for building tools such as code interpreters, or Advanced Data Analysis like in ChatGPT.\n",
    "\n",
    "E2B Data Analysis sandbox allows you to:\n",
    "- Run Python code\n",
    "- Generate charts via matplotlib\n",
    "- Install Python packages dynamically during runtime\n",
    "- Install system packages dynamically during runtime\n",
    "- Run shell commands\n",
    "- Upload and download files\n",
    "\n",
    "We'll create a simple OpenAI agent that will use E2B's Data Analysis sandbox to perform analysis on a uploaded files using Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get your OpenAI API key and [E2B API key here](https://e2b.dev/docs/getting-started/api-key) and set them as environment variables.\n",
    "\n",
    "You can find the full API documentation [here](https://e2b.dev/docs).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to install `e2b` to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%pip install --upgrade --quiet  langchain e2b langchain-community"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain_community.tools import E2BDataAnalysisTool"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"E2B_API_KEY\"] = \"<E2B_API_KEY>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating an instance of the `E2BDataAnalysisTool`, you can pass callbacks to listen to the output of the sandbox. This is useful, for example, when creating more responsive UI. Especially with the combination of streaming output from LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# Artifacts are charts created by matplotlib when `plt.show()` is called\n",
    "def save_artifact(artifact):\n",
    "    print(\"New matplotlib chart generated:\", artifact.name)\n",
    "    # Download the artifact as `bytes` and leave it up to the user to display them (on frontend, for example)\n",
    "    file = artifact.download()\n",
    "    basename = os.path.basename(artifact.name)\n",
    "\n",
    "    # Save the chart to the `charts` directory\n",
    "    with open(f\"./charts/{basename}\", \"wb\") as f:\n",
    "        f.write(file)\n",
    "\n",
    "\n",
    "e2b_data_analysis_tool = E2BDataAnalysisTool(\n",
    "    # Pass environment variables to the sandbox\n",
    "    env_vars={\"MY_SECRET\": \"secret_value\"},\n",
    "    on_stdout=lambda stdout: print(\"stdout:\", stdout),\n",
    "    on_stderr=lambda stderr: print(\"stderr:\", stderr),\n",
    "    on_artifact=save_artifact,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload an example CSV data file to the sandbox so we can analyze it with our agent. You can use for example [this file](https://storage.googleapis.com/e2b-examples/netflix.csv) about Netflix tv shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "with open(\"./netflix.csv\") as f:\n",
    "    remote_path = e2b_data_analysis_tool.upload_file(\n",
    "        file=f,\n",
    "        description=\"Data about Netflix tv shows including their title, category, director, release date, casting, age rating, etc.\",\n",
    "    )\n",
    "    print(remote_path)"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Tool` object and initialize the Langchain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "tools = [e2b_data_analysis_tool.as_tool()]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ask the agent questions about the CSV file we uploaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "agent.run(\n",
    "    \"What are the 5 longest movies on netflix released between 2000 and 2010? Create a chart with their lengths.\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E2B also allows you to install both Python and system (via `apt`) packages dynamically during runtime like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Install Python package\n",
    "e2b_data_analysis_tool.install_python_packages(\"pandas\")"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can download any file from the sandbox like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# The path is a remote path in the sandbox\n",
    "files_in_bytes = e2b_data_analysis_tool.download_file(\"/home/user/netflix.csv\")"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, you can run any shell command inside the sandbox via `run_command`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# Install SQLite\n",
    "e2b_data_analysis_tool.run_command(\"sudo apt update\")\n",
    "e2b_data_analysis_tool.install_system_packages(\"sqlite3\")\n",
    "\n",
    "# Check the SQLite version\n",
    "output = e2b_data_analysis_tool.run_command(\"sqlite3 --version\")\n",
    "print(\"version: \", output[\"stdout\"])\n",
    "print(\"error: \", output[\"stderr\"])\n",
    "print(\"exit code: \", output[\"exit_code\"])"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your agent is finished, don't forget to close the sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "e2b_data_analysis_tool.close()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
